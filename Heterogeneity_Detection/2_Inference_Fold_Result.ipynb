{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8440e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../0_CNN_total_Pytorch_new\")\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import ast\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from src.data_set.segmentation import SegDataset\n",
    "from src.data_set.utils import read_json_as_dict\n",
    "import random\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torch import nn\n",
    "from natsort import natsorted\n",
    "from utils import read_dicom_series_to_array, get_dicom_series_shape, read_nii_to_array, get_nii_shape\n",
    "from utils import resize_dicom_series, write_series_to_path\n",
    "from utils import get_parent_dir_name\n",
    "from volumentations import Compose, ElasticTransform, RandomGamma, GaussianNoise, Transpose, Flip, RandomRotate90, GlassBlur, RandomCrop, GridDropout\n",
    "\n",
    "from itertools import chain\n",
    "import deepspeed\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from src.loss.seg_loss import get_dice_score, get_loss_fn, get_bce_loss_class, accuracy_metric\n",
    "from src.model.inception_resnet_v2.multi_task.multi_task_3d import InceptionResNetV2MultiTask3D\n",
    "from src.util.deepspeed import get_deepspeed_config_dict, average_across_gpus, toggle_grad, load_deepspeed_model_to_torch_model\n",
    "from src.util.common import set_dropout_probability\n",
    "import torch.nn.functional as F\n",
    "from src.model.inception_resnet_v2.multi_task.multi_task_3d import InceptionResNetV2MultiTask3D\n",
    "from src.model.train_util.logger import CSVLogger\n",
    "import torch.distributed as dist\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb689c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_as_nifti(array, output_path, reverse=True):\n",
    "    \n",
    "    if reverse:\n",
    "        array = array[::-1]\n",
    "    # SimpleITK 이미지로 변환\n",
    "    image = sitk.GetImageFromArray(array)\n",
    "    \n",
    "    # 이미지 정보 설정 (spacing, origin, direction 등)\n",
    "    image.SetSpacing((1.0, 1.0, 1.0))  # 임의의 값으로 설정\n",
    "    image.SetOrigin((0.0, 0.0, 0.0))   # 임의의 값으로 설정\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0))  # 단위 행렬로 설정\n",
    "\n",
    "    # SimpleITK 이미지를 NIfTI 형식으로 저장\n",
    "    sitk.WriteImage(image, output_path)\n",
    "\n",
    "def full_data_collate_fn(batch):\n",
    "    # shape 이 달라 list로 따로 들어있다\n",
    "    image_tensor_list, mask_tensor_list = zip(*batch)\n",
    "    return image_tensor_list, mask_tensor_list\n",
    "\n",
    "def apply_augmentation(transform, image_array, mask_array):\n",
    "    transform_dict = transform(image=image_array, mask=mask_array)\n",
    "    \n",
    "    return transform_dict[\"image\"], transform_dict[\"mask\"]\n",
    "\n",
    "def get_augmentation():\n",
    "    return Compose([\n",
    "#         GridDropout(0.5, fill_value=0, mask_fill_value=0, p=1.0),\n",
    "#         ElasticTransform(deformation_limits=(0, 0.15), p=1.0),\n",
    "#         GlassBlur(sigma=0.05, max_delta=2, iterations=2, always_apply=False, mode='fast', p=0.5),\n",
    "#         RandomGamma(gamma_limit=(80, 120), p=0.35),\n",
    "        GaussianNoise(var_limit=(0, 5), p=0.5),\n",
    "#         Transpose(p=0.5),\n",
    "        Flip(0, p=0.5),\n",
    "        Flip(1, p=0.5),\n",
    "        Flip(2, p=0.5),\n",
    "        RandomRotate90((1, 2), p=0.5),\n",
    "    ], p=1.0)\n",
    "\n",
    "def read_image(image_path):\n",
    "    image_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return image_array\n",
    "\n",
    "def image_preprocess(image_array):\n",
    "    min_value, max_value = 0, 255\n",
    "    image_array = image_array.clip(min_value, max_value)\n",
    "    image_array = (image_array - min_value) / (max_value - min_value)\n",
    "    image_array = image_array / 255\n",
    "    return image_array.astype(\"float32\")[None]\n",
    "\n",
    "def mask_preprocess(mask_array):\n",
    "    mask_array = mask_array / 255\n",
    "    return mask_array.astype(\"float32\")\n",
    "\n",
    "def get_partial_3d_model(target_z_dim, num_classes, get_class, get_recon):\n",
    "    return InceptionResNetV2MultiTask3D(input_shape=(1, target_z_dim, 512, 512),\n",
    "                                        class_channel=num_classes, seg_channels=num_classes, validity_shape=(1, 8, 8, 8),\n",
    "                                        inject_class_channel=None,\n",
    "                                        block_size=6, decode_init_channel=None,\n",
    "                                        skip_connect=True, dropout_proba=0.05, norm=\"instace\", act=\"relu6\",\n",
    "                                        class_act=\"softmax\", seg_act=\"softmax\", validity_act=\"sigmoid\",\n",
    "                                        get_seg=True, get_class=get_class, get_recon=get_recon, get_validity=False,\n",
    "                                        use_class_head_simple=True, use_decode_pixelshuffle_only=False, use_decode_simpleoutput=False\n",
    "                                        )\n",
    "def get_log_path(test_model, loss_select, batch_size, target_z_dim, current_fold):\n",
    "    log_path = f\"./result/3d_{test_model}_{loss_select}_{batch_size}\"\n",
    "    log_path = f\"{log_path}_{target_z_dim}\"\n",
    "    if get_class:\n",
    "        log_path = f\"{log_path}_class\"\n",
    "    if get_recon:\n",
    "        log_path = f\"{log_path}_recon\"\n",
    "    log_path = f\"{log_path}_fold_{current_fold}\"\n",
    "    os.makedirs(f\"{log_path}/weights\", exist_ok=True)\n",
    "    return log_path\n",
    "\n",
    "def get_best_dice_epoch(csv_path, select_mode=\"dice_score\"):\n",
    "\n",
    "    select_mode_list = [\"loss\", \"dice_score\", \"dice_score_diff\"]\n",
    "    assert select_mode in select_mode_list, f\"check your select_mode: {select_mode} in {select_mode_list}\"\n",
    "\n",
    "    with open(csv_path) as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        dict_from_csv = {field_name:[] for field_name in reader.fieldnames}    \n",
    "        for row in reader:\n",
    "            for filedname in reader.fieldnames:\n",
    "                dict_from_csv[filedname].append(float(row[filedname]))\n",
    "    if select_mode == \"loss\":\n",
    "        loss_min_epoch = np.argmin(dict_from_csv['val_loss']) + 1\n",
    "        loss_min_loss = np.min(dict_from_csv['val_loss'])\n",
    "        loss_min_score = dict_from_csv['val_dice_score'][loss_min_epoch - 1]\n",
    "        return loss_min_epoch, loss_min_loss, loss_min_score\n",
    "    elif select_mode == \"dice_score\":\n",
    "        score_max_epoch = np.argmax(dict_from_csv['val_dice_score']) + 1\n",
    "        score_max_loss = dict_from_csv['val_loss'][score_max_epoch - 1]\n",
    "        score_max_score = np.max(dict_from_csv['val_dice_score'])\n",
    "        return score_max_epoch, score_max_loss, score_max_score\n",
    "\n",
    "    elif select_mode == \"dice_score_diff\":\n",
    "        min_epoch = 5\n",
    "        val_score = dict_from_csv['val_dice_score'][min_epoch:]\n",
    "        score_diff = np.array(dict_from_csv['dice_score'] - np.array(dict_from_csv['val_dice_score']))[min_epoch:]\n",
    "        score_diff = np.maximum(score_diff, 0)\n",
    "\n",
    "        loss_score_diff_min_epoch = np.argmax(val_score - score_diff) + 1 + min_epoch\n",
    "        loss_score_diff_min_loss = dict_from_csv['val_loss'][loss_score_diff_min_epoch - 1]\n",
    "        loss_score_diff_min_score = dict_from_csv['val_dice_score'][loss_score_diff_min_epoch - 1]\n",
    "        return loss_score_diff_min_epoch, loss_score_diff_min_loss, loss_score_diff_min_score\n",
    "    \n",
    "class SegDataset(Dataset):\n",
    "    def __init__(self, data_folder_list, z_dim_list, target_z_dim, use_full):\n",
    "        self.data_folder_list = data_folder_list\n",
    "        self.z_dim_list = z_dim_list\n",
    "        \n",
    "        self.target_z_dim = target_z_dim\n",
    "        self.use_full = use_full\n",
    "        self.transform = get_augmentation()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_folder_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_folder, z_dim = self.data_folder_list[idx], self.z_dim_list[idx]\n",
    "        image_path = f\"{data_folder}/nii.gz/image.nii.gz\"\n",
    "        mask_path = f\"{data_folder}/nii.gz/mask.nii.gz\"\n",
    "        image_array, mask_array = self.get_array_from_folder(image_path, mask_path, z_dim)\n",
    "        image_array, mask_array = apply_augmentation(self.transform, image_array, mask_array)\n",
    "        image_array = image_preprocess(image_array)\n",
    "        mask_array = mask_preprocess(mask_array)\n",
    "        \n",
    "        return torch.tensor(image_array), torch.tensor(mask_array)\n",
    "    \n",
    "    def get_array_from_folder(self, image_path, mask_path, z_dim):\n",
    "        target_z_dim = self.target_z_dim\n",
    "        \n",
    "        if target_z_dim > z_dim:\n",
    "            z_idx = 0\n",
    "            padding_num = target_z_dim - z_dim\n",
    "            z_idx_range = range(z_idx, min(z_idx + target_z_dim, z_dim))\n",
    "        else:\n",
    "            if self.use_full:\n",
    "                z_idx = 0\n",
    "                padding_num = 0\n",
    "                z_idx_range = range(z_idx, z_dim)\n",
    "            else:\n",
    "                cand_z_idx_list = [idx for idx in range(0, z_dim - target_z_dim)]\n",
    "                z_idx = random.choice(cand_z_idx_list)\n",
    "                padding_num = z_dim - z_idx if z_dim - z_idx < target_z_dim else 0\n",
    "                z_idx_range = range(z_idx, min(z_idx + target_z_dim, z_dim))\n",
    "        top_pad_num = padding_num // 2\n",
    "        bottom_pad_num = padding_num - top_pad_num\n",
    "        \n",
    "        image_array = self.read_nii_gz(image_path)\n",
    "        mask_array = self.read_nii_gz(mask_path)\n",
    "\n",
    "        image_array = image_array[list(z_idx_range)]\n",
    "        mask_array = mask_array[list(z_idx_range)]\n",
    "        image_array = np.pad(image_array, [(top_pad_num, bottom_pad_num), (0, 0), (0, 0)],\n",
    "                             mode=\"constant\", constant_values=0)\n",
    "        mask_array = np.pad(mask_array, [(top_pad_num, bottom_pad_num), (0, 0), (0, 0)],\n",
    "                             mode=\"constant\", constant_values=0)\n",
    "        return image_array, mask_array\n",
    "    \n",
    "    def read_nii_gz(self, nii_path):\n",
    "        image_obj = nib.load(nii_path)\n",
    "        image_array = image_obj.get_fdata()\n",
    "        image_array = image_array.transpose(2, 0, 1)\n",
    "        return image_array\n",
    "\n",
    "class SegDataset(Dataset):\n",
    "    def __init__(self, data_folder_list, z_dim_list, target_z_dim, use_full):\n",
    "        self.data_folder_list = data_folder_list\n",
    "        self.z_dim_list = z_dim_list\n",
    "        \n",
    "        self.target_z_dim = target_z_dim\n",
    "        self.use_full = use_full\n",
    "        self.transform = get_augmentation()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_folder_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_folder, z_dim = self.data_folder_list[idx], self.z_dim_list[idx]\n",
    "        image_path = f\"{data_folder}/nii.gz/image.nii.gz\"\n",
    "        mask_path = f\"{data_folder}/nii.gz/mask.nii.gz\"\n",
    "        image_array, mask_array = self.get_array_from_folder(image_path, mask_path, z_dim)\n",
    "        image_array, mask_array = apply_augmentation(self.transform, image_array, mask_array)\n",
    "        image_array = image_preprocess(image_array)\n",
    "        mask_array = mask_preprocess(mask_array)\n",
    "        \n",
    "        return torch.tensor(image_array), torch.tensor(mask_array)\n",
    "    \n",
    "    def get_array_from_folder(self, image_path, mask_path, z_dim):\n",
    "        target_z_dim = self.target_z_dim\n",
    "        \n",
    "        if target_z_dim > z_dim:\n",
    "            z_idx = 0\n",
    "            padding_num = target_z_dim - z_dim\n",
    "            z_idx_range = range(z_idx, min(z_idx + target_z_dim, z_dim))\n",
    "        else:\n",
    "            if self.use_full:\n",
    "                z_idx = 0\n",
    "                padding_num = 0\n",
    "                z_idx_range = range(z_idx, z_dim)\n",
    "            else:\n",
    "                cand_z_idx_list = [idx for idx in range(0, z_dim - target_z_dim)]\n",
    "                z_idx = random.choice(cand_z_idx_list)\n",
    "                padding_num = z_dim - z_idx if z_dim - z_idx < target_z_dim else 0\n",
    "                z_idx_range = range(z_idx, min(z_idx + target_z_dim, z_dim))\n",
    "        top_pad_num = padding_num // 2\n",
    "        bottom_pad_num = padding_num - top_pad_num\n",
    "        \n",
    "        image_array = self.read_nii_gz(image_path)\n",
    "        mask_array = self.read_nii_gz(mask_path)\n",
    "\n",
    "        image_array = image_array[list(z_idx_range)]\n",
    "        mask_array = mask_array[list(z_idx_range)]\n",
    "        image_array = np.pad(image_array, [(top_pad_num, bottom_pad_num), (0, 0), (0, 0)],\n",
    "                             mode=\"constant\", constant_values=0)\n",
    "        mask_array = np.pad(mask_array, [(top_pad_num, bottom_pad_num), (0, 0), (0, 0)],\n",
    "                             mode=\"constant\", constant_values=0)\n",
    "        return image_array, mask_array\n",
    "    \n",
    "    def read_nii_gz(self, nii_path):\n",
    "        image_obj = nib.load(nii_path)\n",
    "        image_array = image_obj.get_fdata()\n",
    "        image_array = image_array.transpose(2, 0, 1)\n",
    "        return image_array\n",
    "    \n",
    "get_l1_loss = nn.L1Loss()\n",
    "get_l2_loss = nn.MSELoss()\n",
    "# y_recon_pred.shape = [B, C, H, W]\n",
    "def get_recon_loss_follow_seg(y_recon_pred, y_recon_gt, y_seg_pred):\n",
    "    img_dim = y_recon_pred.dim() - 2\n",
    "    repeat_tuple = (1 for _ in range(img_dim))\n",
    "    recon_image_channel = y_recon_pred.size(1)\n",
    "    y_seg_pred_weight = 2 * torch.sigmoid(25 * y_seg_pred[:, 1]) - 1\n",
    "    y_seg_pred_weight = y_seg_pred_weight.unsqueeze(1).repeat(1, recon_image_channel, *repeat_tuple)\n",
    "    recon_loss = torch.abs(y_recon_pred - y_recon_gt) * y_seg_pred_weight\n",
    "    return torch.mean(recon_loss)\n",
    "\n",
    "def compute_loss_metric_full(model, x_list, y_list, target_z_dim, process_batch_size,\n",
    "                             get_class, get_recon, use_class_in_predict, device, dtype):\n",
    "    \n",
    "    y_pred_list, dice_score_list = model_predict_full(model, x_list, y_list, target_z_dim, process_batch_size,\n",
    "                                                      get_class, get_recon, use_class_in_predict, device, dtype)\n",
    "    return y_pred_list, dice_score_list\n",
    "\n",
    "def model_predict_full(model, x_list, y_list, target_z_dim, process_batch_size,\n",
    "                  get_class, get_recon, use_class_in_predict, device, dtype):\n",
    "    with torch.no_grad():\n",
    "        y_pred_list = []\n",
    "        dice_score_list_per_gpu = []\n",
    "        for batch_x, batch_y in zip(x_list, y_list):\n",
    "            batch_x, batch_y = batch_x[None], batch_y[None]\n",
    "            stride = target_z_dim // 4\n",
    "            batch_y_pred = torch.zeros_like(batch_y)\n",
    "            batch_info_list = []\n",
    "            z_dim = batch_x.shape[2]\n",
    "            z_idx_range = range(0, z_dim - target_z_dim + stride, stride)\n",
    "            for idx, z_idx in enumerate(z_idx_range):\n",
    "                x_slice = batch_x[:, :, z_idx:z_idx+target_z_dim]\n",
    "\n",
    "                pad_num = target_z_dim - x_slice.shape[2]\n",
    "                pad_half = pad_num // 2\n",
    "                x_slice = F.pad(x_slice, (0, 0, 0, 0, pad_half, pad_num - pad_half), \"constant\", 0)\n",
    "                batch_info_list.append([z_idx, pad_num, x_slice])\n",
    "\n",
    "                if len(batch_info_list) == process_batch_size or idx < len(z_idx_range):\n",
    "                    slice_batch = [batch_info[-1] for batch_info in batch_info_list]\n",
    "                    slice_batch = torch.cat(slice_batch, dim=0).to(device=device, dtype=dtype)\n",
    "\n",
    "                    if get_class and get_recon:\n",
    "                        batch_predict, batch_label_predict, batch_recon_predict = model(slice_batch)\n",
    "                    elif get_class:\n",
    "                        batch_predict, batch_label_predict = model(slice_batch)\n",
    "                    elif get_recon:\n",
    "                        batch_predict, batch_recon_predict = model(slice_batch)\n",
    "                    else:\n",
    "                        batch_predict = model(slice_batch)\n",
    "\n",
    "                    if get_class and use_class_in_predict:\n",
    "                        # batch_indices.shape = [B, C]\n",
    "                        # batch_predict.shape = [B, C, D, H, W]\n",
    "                        batch_predict = batch_predict * batch_label_predict[:, :, None, None, None]\n",
    "\n",
    "                    for idx, (slice_z_idx, pad_num) in enumerate([batch_info[:2] for batch_info in batch_info_list]):\n",
    "                        pad_half = pad_num // 2\n",
    "                        y_slice_pred = batch_predict[idx][None]\n",
    "                        start_idx = slice_z_idx\n",
    "                        end_idx = min(slice_z_idx + target_z_dim, z_dim)\n",
    "                        z_slice = slice(start_idx, end_idx)\n",
    "                        # total - pad_num => total - pad_num + pad_half\n",
    "                        part_z_slice = slice(pad_half, end_idx - slice_z_idx + pad_half)\n",
    "                        previous_slice = batch_y_pred[:, z_slice]\n",
    "                        current_slice = y_slice_pred[:, :, part_z_slice].argmax(1).cpu()\n",
    "                        batch_y_pred[:, z_slice] = torch.maximum(previous_slice, current_slice)\n",
    "                    batch_info_list = []\n",
    "            y_pred_list.append(batch_y_pred)\n",
    "\n",
    "        for y_pred, y in zip(y_pred_list, y_list):\n",
    "            epsilon = 1e-7\n",
    "            y_pred, y = y_pred[0].numpy(), y[0].numpy()\n",
    "            tp = np.sum(y_pred * y)\n",
    "            fp = np.sum(y_pred) - tp\n",
    "            fn = np.sum(y) - tp\n",
    "            dice_score = (2 * tp + epsilon) / (2 * tp + fp + fn + epsilon)\n",
    "            dice_score = torch.tensor(dice_score).to(device=device, dtype=dtype)\n",
    "            dice_score_list_per_gpu.append(dice_score)\n",
    "    \n",
    "    return y_pred_list, dice_score_list_per_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1772bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "\n",
    "target_z_dim = 32\n",
    "loss_list = [\"dice_bce\", \"dice_bce_focal\", \"tversky_bce\", \"propotional_bce\"]\n",
    "\n",
    "total_epoch = 10\n",
    "stage_coef_list = [2, 5]\n",
    "decay_epoch = total_epoch - sum(stage_coef_list)\n",
    "decay_dropout_ratio = 0.25 ** (1  / (total_epoch - sum(stage_coef_list)))\n",
    "lr_setting_list = [4e-5, 2e-4, 0.25]\n",
    "\n",
    "test_model = \"unet_custom\"\n",
    "loss_select = \"propotional_bce\"\n",
    "in_channels = 1\n",
    "num_classes = 2\n",
    "get_class = True\n",
    "get_recon = True\n",
    "use_seg_in_recon = True\n",
    "\n",
    "batch_size = 2\n",
    "num_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33ed3bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 92\n",
      "model_param_num = 24001133\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "meta_df_path = f\"./phase.csv\"\n",
    "check_result_folder = \"./check_output\"\n",
    "for current_fold in range(n_fold):\n",
    "    test_fold = current_fold\n",
    "    check_result_fold_folder = f\"{check_result_folder}/fold_{current_fold}\"\n",
    "    os.makedirs(check_result_fold_folder)\n",
    "    \n",
    "    meta_df_base, meta_df_ext = os.path.splitext(meta_df_path)\n",
    "    meta_fold_df_path = f\"{meta_df_base}_fold{meta_df_ext}\"\n",
    "    assert os.path.exists(meta_fold_df_path), \"check meta_fold_df_path existence\"\n",
    "    meta_fold_df = pd.read_csv(meta_fold_df_path)\n",
    "\n",
    "    test_folder_list = list(meta_fold_df[meta_fold_df[\"Fold\"] == test_fold][\"data_folder\"])\n",
    "    test_z_dim_list = list(meta_fold_df[meta_fold_df[\"Fold\"] == test_fold][\"Depth\"])\n",
    "    test_dataset = SegDataset(test_folder_list, test_z_dim_list, target_z_dim, use_full=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, collate_fn=full_data_collate_fn, shuffle=False)\n",
    "    print(f\"test: {len(test_dataset)}\")\n",
    "    model = get_partial_3d_model(target_z_dim, num_classes, get_class, get_recon)\n",
    "    model_param_num = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"model_param_num = {model_param_num}\")\n",
    "    log_path = get_log_path(test_model, loss_select, batch_size, target_z_dim, current_fold)\n",
    "    weight_path = f\"{log_path}/weights/{total_epoch:03d}.ckpt\"\n",
    "    load_deepspeed_model_to_torch_model(model, weight_path)\n",
    "    model = model.to(device=device).eval()\n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "        for batch_idx, (x_list, y_list) in test_pbar:\n",
    "            y_pred_list, dice_score_list = compute_loss_metric_full(model, x_list, y_list, target_z_dim, process_batch_size=batch_size, \n",
    "                                                                   get_class=get_class, get_recon=get_recon, use_class_in_predict=False, \n",
    "                                                                   device=device, dtype=dtype)\n",
    "            batch_test_folder_list = test_folder_list[batch_size * batch_idx:batch_size * (batch_idx + 1)]\n",
    "            for test_folder, x, y, y_pred, dice_score in zip(batch_test_folder_list, x_list, y_list, y_pred_list, dice_score_list):\n",
    "                data_basename = os.path.basename(test_folder)\n",
    "                output_folder = f\"{check_result_fold_folder}/{dice_score:.3f}_{data_basename}\"\n",
    "                os.makedirs(output_folder, exists_ok=True)\n",
    "                image_path = f\"{output_folder}/image.nii.gz\"\n",
    "                mask_path = f\"{output_folder}/mask.nii.gz\"\n",
    "                pred_path = f\"{output_folder}/pred.nii.gz\"\n",
    "                \n",
    "                x, y, y_pred = x.numpy(), y.numpy(), y_pred.numpy()\n",
    "                save_array_as_nifti(x, image_path)\n",
    "                save_array_as_nifti(y, mask_path)\n",
    "                save_array_as_nifti(y_pred, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167dc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
